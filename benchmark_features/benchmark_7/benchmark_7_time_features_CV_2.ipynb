{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for measuring performance of engineered features and models\n",
    "\n",
    "Use all the time series features to in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c3se/NOBACKUP/users/lyaa/conda_dir/miniconda/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../bosch_helper')\n",
    "from bosch_helper import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Featrues\n",
    "\n",
    "First do Fourier transform or autocorrelation on the time series, find the period in time. Then create the following features:\n",
    "- StartStationTimes\n",
    "    * Start time on each station\n",
    "- StartTime, EndTime, Duration\n",
    "    * Overall start and end time and duration of production\n",
    "- StationTimeDiff\n",
    "    * The time interval between two neighboring stations?\n",
    "- Start/End part of week (mod 1680)\n",
    "    * Fourier transform\n",
    "    * Autocorrelation\n",
    "- Number of records in next/last 2.5h, 24h, 168h for each station\n",
    "    * First convert numeric to `deltatime` by `x['time_start'] = pd.to_deltatime(x['time_start'], unit='h')`\n",
    "    * `df.rolling(window='60min', on='time_start')['counts'].sum()`\n",
    "- Number of records in the same time (6 mins)\n",
    "- MeanTimeDiff since last 1/5/10 failure(s)\n",
    "- MeanTimeDiff till next 1/5/10 failure(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important numeric features are imported\n",
    "important_features = pd.read_csv('../benchmark_1/important_numeric_features.csv', index_col=0, header=None)\n",
    "important_features = list(important_features.values.ravel())\n",
    "important_features.extend(['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_numeric = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, usecols=important_features, dtype=np.float32)\n",
    "\n",
    "y_train = x_train_numeric.Response\n",
    "x_train_numeric.drop(['Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = pd.read_csv('../benchmark_2/train_station_flow.csv.gz', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_numeric.join(date_train)\n",
    "\n",
    "columns = list(x_train.columns)\n",
    "columns[-1] = 'station_flow'\n",
    "x_train.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_numeric = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, usecols=important_features[:-1], dtype=np.float32)\n",
    "\n",
    "date_test = pd.read_csv('../benchmark_2/test_station_flow.csv.gz', index_col=0, header=None)\n",
    "\n",
    "x_test = x_test_numeric.join(date_test)\n",
    "x_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index = x_train.index.astype(np.int64)\n",
    "x_test.index = x_test.index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train_numeric, x_test_numeric\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_chunk = pd.read_csv('../benchmark_3/start_chunk.csv.gz', index_col=0)\n",
    "\n",
    "start_chunk_train = start_chunk.loc[start_chunk.Response!=-1].drop(['Response'], axis=1)\n",
    "start_chunk_test = start_chunk.loc[start_chunk.Response==-1].drop(['Response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.join(start_chunk_train, on='Id')\n",
    "x_test = x_test.join(start_chunk_test, on='Id')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.read_csv('../benchmark_4/benchmark_4_neighbors.csv.gz', index_col=0)\n",
    "\n",
    "neighbor_train = n.loc[n.Response!=-1]\n",
    "neighbor_train.drop(['Response'], axis=1, inplace=True)\n",
    "\n",
    "neighbor_test = n.loc[n.Response==-1]\n",
    "neighbor_test.drop(['Response'], axis=1, inplace=True)\n",
    "\n",
    "print(neighbor_test.shape, neighbor_train.shape)\n",
    "\n",
    "x_train = x_train.join(neighbor_train, on='Id')\n",
    "x_test = x_test.join(neighbor_test, on='Id')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add neighbor numeric features\n",
    "The important numeric features selected from previous and next records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date + station flow data will be added to x\n",
    "x = pd.concat([x_train, x_test], keys=['train', 'test'])\n",
    "x.sort_index(axis=0, level='Id', inplace=True)\n",
    "\n",
    "# Add the neighbor records\n",
    "x = x.join(x.iloc[:, :150].shift(), rsuffix='_previous')\n",
    "x = x.join(x.iloc[:, :150].shift(-1), rsuffix='_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x.loc['train']\n",
    "x_test = x.loc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_7 features\n",
    "\n",
    "Time series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = pd.read_hdf('time_features_diff.hdf', 'time_features')\n",
    "time_features.drop(['time_start', 'time_end', 'time_duration', 'Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff_cols = time_features.iloc[:, -40:].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not use MeanTimeDiff features\n",
    "x_train = x_train.join(time_features.loc['train'])\n",
    "x_test = x_test.join(time_features.loc['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del time_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.drop(['Response'], axis=1, inplace=True)\n",
    "# x_test.drop(['Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV score based on stratified KFold with repeated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV\n",
    "# specify parameters \n",
    "# 'booster':'gbtree'\n",
    "params = {'max_depth':14, 'eta':0.03, 'silent':1, 'objective':'binary:logistic', 'nthread':20,\n",
    "         'lambda':4, 'subsample':0.9, 'min_child_weight':5, 'booster':'gbtree', 'alpha':0,\n",
    "         'base_score':0.0058, 'colsample_bytree':0.6}\n",
    "\n",
    "# 'booster':'dart'\n",
    "# params = {'max_depth':14, 'eta':0.03, 'silent':1, 'objective':'binary:logistic', 'nthread':20,\n",
    "#         'lambda':4, 'subsample':0.9, 'min_child_weight':5, 'booster':'dart', 'alpha':0,\n",
    "#         'base_score':0.0058, 'nthread':20, 'colsample_bytree':0.6, \n",
    "#         'sample_type':'uniform', 'normalize_type':'tree', 'rate_drop':0.1, 'skip_drop':0.2, 'one_drop':True}\n",
    "\n",
    "cv_results, clfs, running_time = cross_val_predict_skf_rm_xgb(params, x_train, y_train, \n",
    "                                                              num_boost_round=80, n_splits=5, \n",
    "                                                              n_repeats=3, random_state=59475038, \n",
    "                                                              verbose_eval=True)\n",
    "\n",
    "results = {'clfs': clfs, 'cv_results': cv_results, 'running_time': running_time}\n",
    "save_pickle(results, 'results_benchmark_7_time_features_cv_1.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_mean = cv_results['train'].mean(axis=1)\n",
    "cv_train_std = cv_results['train'].std(axis=1)\n",
    "cv_test_mean = cv_results['test'].mean(axis=1)\n",
    "cv_test_std = cv_results['test'].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(np.arange(len(cv_train_mean)), cv_train_mean)\n",
    "plt.fill_between(np.arange(len(cv_train_mean)), cv_train_mean-cv_train_std, cv_train_mean+cv_train_std, alpha=0.5)\n",
    "plt.plot(np.arange(len(cv_train_mean)), cv_test_mean)\n",
    "plt.fill_between(np.arange(len(cv_test_mean)), cv_test_mean-cv_test_std, cv_test_mean+cv_test_std, alpha=0.5)\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "params['seed'] = 28537894\n",
    "clf = xgb.train(params, dtrain, num_boost_round=60,\n",
    "               feval=mcc_eval, evals=[(dtrain, 'train')])\n",
    "\n",
    "y_train_pred = clf.predict(dtrain)\n",
    "\n",
    "# Find best threshold \n",
    "thresholds = np.linspace(0.01, 0.99, 400)\n",
    "mcc = np.array([matthews_corrcoef(y_train, y_train_pred>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "\n",
    "print('Optimal MCC = {:.3f}'.format(mcc.max()))\n",
    "print('Optimal threshold = {:.3f}'.format(best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "y_test_pred = clf.predict(dtest)\n",
    "y_test_pred_int = (y_test_pred>best_threshold).astype(int)\n",
    "\n",
    "sub = pd.read_csv(\"../../data/sample_submission.csv.zip\", index_col=0)\n",
    "sub[\"Response\"] = y_test_pred_int\n",
    "sub.to_csv(\"15-benchmark_7_submission_1.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only With MeanTimeDiff Features:\n",
    "- LB: `n_estimators=60`: Private MCC = 0.44401, public MCC = 0.43569\n",
    "- CV: `n_estimators=80`: Score mean = 0.448, std = 0.013\n",
    "- CV: `n_estimators=60`: Score mean = 0.445491, std = 0.0133, MCC~[0.43218, 0.45880]\n",
    "\n",
    "Time series features, excluding MeanTimeDiff:\n",
    "- LB: `n_estimators=60`: Private MCC = 0.46212, public MCC = 0.44761\n",
    "- CV: `n_estimators=80`: Score mean = 0.454509, std = 0.00586\n",
    "- CV: `n_estimators=60`: Score mean = 0.4534794, std = 0.0067, MCC~[0.44682, 0.46014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_test_mean[60]+cv_test_std[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_mean[60]-cv_test_std[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_mean[79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
