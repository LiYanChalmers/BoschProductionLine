{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for measuring performance of engineered features and models\n",
    "Add features created from previous and next records in original order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c3se/NOBACKUP/users/lyaa/conda_dir/miniconda/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sys import getsizeof\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from scipy import fftpack\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(x, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pickle(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "\n",
    "@jit\n",
    "def eval_mcc(y_true, y_prob, show=False):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true) # number of positive\n",
    "    numn = n - nump # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    prev_proba = -1\n",
    "    best_proba = -1\n",
    "    mccs = np.zeros(n)\n",
    "    new_mcc = 0\n",
    "    for i in range(n):\n",
    "        # all items with idx < i are predicted negative while others are predicted positive\n",
    "        # only evaluate mcc when probability changes\n",
    "        proba = y_prob[idx[i]]\n",
    "        if proba != prev_proba:\n",
    "            prev_proba = proba\n",
    "            new_mcc = mcc(tp, tn, fp, fn)\n",
    "            if new_mcc >= best_mcc:\n",
    "                best_mcc = new_mcc\n",
    "                best_id = i\n",
    "                best_proba = proba\n",
    "        mccs[i] = new_mcc\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "    if show:\n",
    "        y_pred = (y_prob >= best_proba).astype(int)\n",
    "        score = matthews_corrcoef(y_true, y_pred)\n",
    "        print(score, best_mcc)\n",
    "        plt.plot(mccs)\n",
    "        return best_proba, best_mcc, y_pred\n",
    "    else:\n",
    "        return best_mcc\n",
    "    \n",
    "def mcc_eval(y_prob, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    best_mcc = eval_mcc(y_true, y_prob)\n",
    "    return 'MCC', best_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_rskf(clf, x_train, y_train, n_splits=3, \n",
    "                           n_repeats=2, random_state=42, verbose=False, early_stopping=10):\n",
    "    '''\n",
    "    Repeated stratified KFold CV, returns predictions for \n",
    "    each repeat and average score.\n",
    "    n_repeats: repetitions of CV\n",
    "    to disable erlay stopping, set early_stopping to None\n",
    "    '''\n",
    "    scores = []\n",
    "    n_trees = []\n",
    "    clfs = []\n",
    "    running_time = []\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_repeats=n_repeats, n_splits=n_splits, \n",
    "                                   random_state=0)\n",
    "    np.random.seed(random_state)\n",
    "    for n, (train_index, test_index) in enumerate(rskf.split(x_train, y_train)):\n",
    "        print('Round {}'.format(n))\n",
    "        start_time = time.time()\n",
    "        x_train_tmp, x_test_tmp = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "        y_train_tmp, y_test_tmp = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        clf.random_state = np.random.randint(10000000)\n",
    "        \n",
    "        if early_stopping is not None:\n",
    "            clf.fit(x_train_tmp, y_train_tmp, \n",
    "                    eval_set=[(x_test_tmp, y_test_tmp)], \n",
    "                    eval_metric=mcc_eval, early_stopping_rounds=early_stopping,\n",
    "                    verbose=verbose)\n",
    "            scores.append(-clf.best_score)\n",
    "            n_trees.append(clf.best_ntree_limit)\n",
    "        else:\n",
    "            clf.fit(x_train_tmp, y_train_tmp)\n",
    "            scores.append(eval_mcc(y_test_tmp.values, clf.predict_proba(x_test_tmp)[:, 1]))\n",
    "            n_trees.append(clf.n_estimators)\n",
    "        \n",
    "        clfs.append(clf)\n",
    "        running_time.append(time.time()-start_time)\n",
    "        print('Split {}, score = {:.3f}, best_ntree_limit = {}, total time = {:.3f} min'.format(n, scores[n], \n",
    "            n_trees[n], sum(running_time)/60))\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return clfs, scores, n_trees, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_skf_rm(clf, x_train, y_train, n_splits=3, \n",
    "                           n_repeats=2, random_state=42, verbose=False, early_stopping=10):\n",
    "    '''\n",
    "    Stratified KFold CV with repeated models\n",
    "    to disable erlay stopping, set early_stopping to None\n",
    "    '''\n",
    "    scores = []\n",
    "    n_trees = []\n",
    "    clfs = []\n",
    "    running_time = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for m in range(n_repeats):\n",
    "        print('Repeat {}'.format(m))\n",
    "        for n, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "            start_time = time.time()\n",
    "            x_train_tmp, x_test_tmp = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "            y_train_tmp, y_test_tmp = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "            clf.random_state = np.random.randint(10000000)\n",
    "            # print(clf.random_state)\n",
    "\n",
    "            if early_stopping is not None:\n",
    "                clf.fit(x_train_tmp, y_train_tmp, \n",
    "                        eval_set=[(x_test_tmp, y_test_tmp)], \n",
    "                        eval_metric=mcc_eval, early_stopping_rounds=early_stopping,\n",
    "                        verbose=verbose)\n",
    "                scores.append(-clf.best_score)\n",
    "                n_trees.append(clf.best_ntree_limit)\n",
    "            else:\n",
    "                clf.fit(x_train_tmp, y_train_tmp)\n",
    "                scores.append(eval_mcc(y_test_tmp.values, clf.predict_proba(x_test_tmp)[:, 1]))\n",
    "                n_trees.append(clf.n_estimators)\n",
    "            \n",
    "            clfs.append(clf)\n",
    "            running_time.append(time.time() - start_time)\n",
    "            print('Split {}, score = {:.3f}, n_best_trees = {}, total time = {:.3f} min'.format(n, \n",
    "                scores[m*n_repeats+n], n_trees[m*n_repeats+n], sum(running_time)/60))\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return clfs, scores, n_trees, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_skf_rm_xgb(params, x_train, y_train, num_boost_round=3, n_splits=3, \n",
    "                           n_repeats=2, random_state=3795264, verbose_eval=False):\n",
    "    '''\n",
    "    Stratified KFold CV with repeated models\n",
    "    Early stopping is totally disabled\n",
    "    Uses xgb.cv API\n",
    "    verbose_eval is the same as in xgb.train\n",
    "    '''\n",
    "    cv_results = {}\n",
    "    clfs = {}\n",
    "    running_time = {}\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=np.random.randint(10**6), shuffle=True)\n",
    "    \n",
    "    for m in range(n_repeats):\n",
    "        for n, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Construct DMatrix\n",
    "            dtrain = xgb.DMatrix(x_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "            dtest = xgb.DMatrix(x_train.iloc[test_index], label=y_train.iloc[test_index])\n",
    "            \n",
    "            # Placeholder for evals_result\n",
    "            cv_results[m, n] = {}\n",
    "            params['seed'] = np.random.randint(10**6)\n",
    "            clfs[m, n] = xgb.train(params, dtrain, num_boost_round=num_boost_round,\n",
    "                                   evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "                                  feval=mcc_eval, maximize=True, early_stopping_rounds=None, \n",
    "                                  evals_result=cv_results[m, n], verbose_eval=verbose_eval)\n",
    "        \n",
    "            running_time[m, n] = time.time() - start_time\n",
    "            \n",
    "            print('Repeat {}, split {}, test MCC = {:.3f}, running time = {:.3f} min'.format(m, n, \n",
    "                cv_results[m, n]['test']['MCC'][-1], running_time[m, n]/60))\n",
    "        \n",
    "    # Post-process cv_results\n",
    "    cv_results_final = {}\n",
    "    for m in range(n_repeats):\n",
    "        for n in range(n_splits):\n",
    "            cv_results_final['train', m, n] = cv_results[m, n]['train']['MCC']\n",
    "            cv_results_final['test', m, n] = cv_results[m, n]['test']['MCC']\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(cv_results_final)\n",
    "    df.index.name = 'iteration'\n",
    "    df.columns.names = ['dataset', 'repeat', 'split']\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(df['test'].iloc[-1].mean(), df['test'].iloc[-1].std()))\n",
    "    \n",
    "    return df, clfs, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference_to_failures(x, failure_max):\n",
    "    '''\n",
    "    Find the average time difference to the last and next failure_max failures.\n",
    "    x should have ['Response', 'time_start', 'time_end']\n",
    "    '''\n",
    "    \n",
    "    u = x[['Response', 'time_start']].copy()\n",
    "    u.columns = ['Response', 'time']\n",
    "    x_start = time_difference_to_failures_helper(u, failure_max, '_start')\n",
    "    \n",
    "    u = x[['Response', 'time_end']].copy()\n",
    "    u.columns = ['Response', 'time']\n",
    "    x_end = time_difference_to_failures_helper(u, failure_max, '_end')\n",
    "    \n",
    "    return x_start.join(x_end)\n",
    "\n",
    "def time_difference_to_failures_helper(x, failure_max, suffix):\n",
    "    '''\n",
    "    Find the mean time difference since last/next 1, 2, ..., failure_max failures\n",
    "    when samples are sorted by the time column\n",
    "    suffix is used for column names of the final results\n",
    "    x is a DataFrame containing:\n",
    "    - Both train and test data\n",
    "    - Two columns: Response and a time column, \n",
    "        which is used to sort samples and calculate time differences\n",
    "    '''\n",
    "    \n",
    "    # sort by time and Id\n",
    "    x.sort_values(['time', 'Id'], inplace=True)\n",
    "    x.Response.fillna(0, inplace=True)\n",
    "    x.Response = x.Response.astype(np.int8)\n",
    "    \n",
    "    # ranking in sorted order\n",
    "    x['rank_sort_time'] = np.arange(1, len(x)+1)\n",
    "    \n",
    "    # rank of failures\n",
    "    x['rank_failure'] = x['Response']\n",
    "    x['rank_failure'] = x['rank_failure'].cumsum()\n",
    "    x.loc[x['Response']!=1, 'rank_failure'] = 0\n",
    "    \n",
    "    # the rank_failure of the 1st previous failure for each sample\n",
    "    # for the first several samples without previous failures, use 0\n",
    "    x['fp1'] = x['rank_failure'].shift().fillna(0).astype(np.int64)\n",
    "    x['fp1'] = x['fp1'].cummax()\n",
    "    x['fp1'] = x['fp1'].astype(np.int64)\n",
    "    \n",
    "    # the failure rank of the 2nd to failure_max previous failure for each sample\n",
    "    failure_list = np.arange(2, failure_max+1)\n",
    "    for f in failure_list:\n",
    "        x['fp'+str(f)] = x['fp'+str(f-1)]-1\n",
    "        x.loc[x['fp'+str(f)]<0, 'fp'+str(f)] = 0\n",
    "        x['fp'+str(f)] = x['fp'+str(f)].astype(np.int64)\n",
    "        \n",
    "    # the failure rank of the 1st next failure for each sample\n",
    "    # for the last several samples do not have next failure, use failure_count+1\n",
    "    failure_count = sum(x['Response'])\n",
    "    x['fn1'] = x['fp1'].shift(-1).fillna(failure_count)+1\n",
    "    # the total number of failures\n",
    "    # assign np.nan to rows whose rank_failure is larger than failure_count\n",
    "    x.loc[x['fn1']>failure_count, 'fn1'] = failure_count+1\n",
    "    x['fn1'] = x['fn1'].astype(np.int64)\n",
    "\n",
    "    # the failure rank of the 2nd to failure_max (failure_max=10 here) next failure for each sample\n",
    "    for f in failure_list:\n",
    "        x['fn'+str(f)] = x['fn'+str(f-1)]+1\n",
    "        x.loc[x['fn'+str(f)]>failure_count, 'fn'+str(f)] = failure_count+1\n",
    "        x['fn'+str(f)] = x['fn'+str(f)].astype(np.int64)\n",
    "        \n",
    "    # a mapping from failure rank to start time of the failure\n",
    "    rank_failure_to_time = x.loc[x['rank_failure']!=0, ['rank_failure', 'time']].set_index(\n",
    "        'rank_failure', drop=True, inplace=False)\n",
    "    rank_failure_to_time = rank_failure_to_time.to_dict()\n",
    "    rank_failure_to_time = rank_failure_to_time['time']\n",
    "    rank_failure_to_time[0] = np.nan\n",
    "    rank_failure_to_time[failure_count+1] = np.nan\n",
    "    \n",
    "    # map from failure rank to time of the failure \n",
    "    for f in range(1, failure_max+1):\n",
    "        x['fp{}_time'.format(f)] = x['fp'+str(f)].map(rank_failure_to_time)\n",
    "        \n",
    "    # map from failure rank to time of the failure \n",
    "    for f in range(1, failure_max+1):\n",
    "        x['fn{}_time'.format(f)] = x['fn'+str(f)].map(rank_failure_to_time)\n",
    "        \n",
    "    # Calculate average of the next n failures\n",
    "    ave_list = []\n",
    "    for f in range(1, failure_max+1):\n",
    "        ave_list.append('fn{}_time'.format(f))\n",
    "        x['fn{}_time_ave{}'.format(f, suffix)] = x[ave_list].mean(axis=1) - x['time']\n",
    "\n",
    "    # Calculate average of the previous n failures\n",
    "    ave_list = []\n",
    "    for f in range(1, failure_max+1):\n",
    "        ave_list.append('fp{}_time'.format(f))\n",
    "        x['fp{}_time_ave{}'.format(f, suffix)] = x[ave_list].mean(axis=1) - x['time']\n",
    "        \n",
    "    # drop auxiliary columns\n",
    "    drop_list = [k for i in range(1, failure_max+1) for k in ['fp'+str(i), 'fn'+str(i)]]\n",
    "    drop_list.extend([k for f in range(1, failure_max+1) for k in ['fp'+str(f)+'_time', 'fn'+str(f)+'_time']])\n",
    "    drop_list.extend(['time', 'rank_sort_time', 'rank_failure', 'Response'])\n",
    "    x.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    # sort index\n",
    "    x.sort_index(by='Id', axis=0, inplace=True)    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_time(time_features, by):\n",
    "    # Create time slot identifier for start time\n",
    "    u = time_features.groupby(by)[by].count()\n",
    "    u.name = 'count_'+by\n",
    "    u = pd.DataFrame(u)\n",
    "    u.reset_index(drop=False, inplace=True)\n",
    "    u.reset_index(drop=False, inplace=True)\n",
    "    u.drop(['count_'+by], axis=1, inplace=True)\n",
    "    u.columns = ['rank_'+by, by]\n",
    "    u.set_index(by, drop=True, inplace=True)\n",
    "    time_features = time_features.join(u, on=by)\n",
    "    \n",
    "    return time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_recent(x, suffix, time_windows=['60min', '150min', '1440min', '10080min']):\n",
    "    '''\n",
    "    Count number of recent records within the given time windows both in forward and backward directions\n",
    "    '''\n",
    "    x = x.sort_values(by='time')\n",
    "    x.time = x.time/0.1\n",
    "    x = x.fillna(x.max()+2000)\n",
    "    x.time = pd.to_timedelta(x.time, unit='h')\n",
    "    x['dummy'] = 1\n",
    "\n",
    "    # Time windows \n",
    "    #     time_windows = ['60min', '150min', '1440min', '10080min']\n",
    "    # Group by start time\n",
    "    u = pd.DataFrame(x.groupby('time')['time'].count())\n",
    "    u.columns = ['counts']\n",
    "    u.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    # identifier to each time slot\n",
    "    u['rank_time'] = np.arange(len(u))\n",
    "    \n",
    "    # Backward looking time windows\n",
    "    for t in time_windows:\n",
    "        u['counts_last_{}{}'.format(t, suffix)] = u.rolling(t, on='time')['counts'].sum()\n",
    "\n",
    "    # Construct forward looking time window\n",
    "    u['time_negative'] = -u['time']\n",
    "    u.sort_values('time_negative', inplace=True)\n",
    "    for t in time_windows:\n",
    "        u['counts_next_{}{}'.format(t, suffix)] = u.rolling(t, on='time_negative')['counts'].sum()\n",
    "    u.sort_values(by='time', inplace=True)\n",
    "\n",
    "    # Drop auxiliary columns \n",
    "    u.drop(['time_negative', 'counts', 'time'], axis=1, inplace=True)\n",
    "    u.set_index('rank_time', inplace=True, drop=True)\n",
    "    \n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Featrues\n",
    "\n",
    "First do Fourier transform or autocorrelation on the time series, find the period in time. Then create the following features:\n",
    "- StartStationTimes\n",
    "    * Start time on each station\n",
    "- StartTime, EndTime, Duration\n",
    "    * Overall start and end time and duration of production\n",
    "- StationTimeDiff\n",
    "    * The time interval between two neighboring stations?\n",
    "- Start/End part of week (mod 1680)\n",
    "    * Fourier transform\n",
    "    * Autocorrelation\n",
    "- Number of records in next/last 2.5h, 24h, 168h for each station\n",
    "    * First convert numeric to `deltatime` by `x['time_start'] = pd.to_deltatime(x['time_start'], unit='h')`\n",
    "    * `df.rolling(window='60min', on='time_start')['counts'].sum()`\n",
    "- Number of records in the same time (6 mins)\n",
    "- MeanTimeDiff since last 1/5/10 failure(s)\n",
    "- MeanTimeDiff till next 1/5/10 failure(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important numeric features are imported\n",
    "important_features = pd.read_csv('../benchmark_1/important_numeric_features.csv', index_col=0, header=None)\n",
    "important_features = list(important_features.values.ravel())\n",
    "important_features.extend(['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_numeric = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, usecols=important_features, dtype=np.float32)\n",
    "\n",
    "y_train = x_train_numeric.Response\n",
    "x_train_numeric.drop(['Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = pd.read_csv('../benchmark_2/train_station_flow.csv.gz', index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_numeric.join(date_train)\n",
    "\n",
    "columns = list(x_train.columns)\n",
    "columns[-1] = 'station_flow'\n",
    "x_train.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_numeric = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, usecols=important_features[:-1], dtype=np.float32)\n",
    "\n",
    "date_test = pd.read_csv('../benchmark_2/test_station_flow.csv.gz', index_col=0, header=None)\n",
    "\n",
    "x_test = x_test_numeric.join(date_test)\n",
    "x_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index = x_train.index.astype(np.int64)\n",
    "x_test.index = x_test.index.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x_train_numeric, x_test_numeric\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_chunk = pd.read_csv('../benchmark_3/start_chunk.csv.gz', index_col=0)\n",
    "\n",
    "start_chunk_train = start_chunk.loc[start_chunk.Response!=-1].drop(['Response'], axis=1)\n",
    "start_chunk_test = start_chunk.loc[start_chunk.Response==-1].drop(['Response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.join(start_chunk_train, on='Id')\n",
    "x_test = x_test.join(start_chunk_test, on='Id')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_4 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183748, 14) (1183747, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = pd.read_csv('../benchmark_4/benchmark_4_neighbors.csv.gz', index_col=0)\n",
    "\n",
    "neighbor_train = n.loc[n.Response!=-1]\n",
    "neighbor_train.drop(['Response'], axis=1, inplace=True)\n",
    "\n",
    "neighbor_test = n.loc[n.Response==-1]\n",
    "neighbor_test.drop(['Response'], axis=1, inplace=True)\n",
    "\n",
    "print(neighbor_test.shape, neighbor_train.shape)\n",
    "\n",
    "x_train = x_train.join(neighbor_train, on='Id')\n",
    "x_test = x_test.join(neighbor_test, on='Id')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add neighbor numeric features\n",
    "The important numeric features selected from previous and next records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date + station flow data will be added to x\n",
    "x = pd.concat([x_train, x_test], keys=['train', 'test'])\n",
    "x.sort_index(axis=0, level='Id', inplace=True)\n",
    "\n",
    "# Add the neighbor records\n",
    "x = x.join(x.iloc[:, :150].shift(), rsuffix='_previous')\n",
    "x = x.join(x.iloc[:, :150].shift(-1), rsuffix='_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x.loc['train']\n",
    "x_test = x.loc['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benchmark_7 features\n",
    "\n",
    "Time series features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = pd.read_hdf('time_features_diff.hdf', 'time_features')\n",
    "time_features.drop(['time_start', 'time_end', 'time_duration', 'Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_diff_cols = time_features.iloc[:, -40:].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not use MeanTimeDiff features\n",
    "x_train = x_train.join(time_features.loc['train'].iloc[:, :-40])\n",
    "x_test = x_test.join(time_features.loc['test'].iloc[:, :-40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1183747, 754) (1183748, 754)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del time_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.drop(['Response'], axis=1, inplace=True)\n",
    "# x_test.drop(['Response'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV score based on stratified KFold with repeated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.314385\ttest-MCC:0.306742\n",
      "[1]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.322786\ttest-MCC:0.311309\n",
      "[2]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.356952\ttest-MCC:0.345125\n",
      "[3]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.372043\ttest-MCC:0.357245\n",
      "[4]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.385805\ttest-MCC:0.361683\n",
      "[5]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.402828\ttest-MCC:0.361431\n",
      "[6]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.414868\ttest-MCC:0.367235\n",
      "[7]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.429316\ttest-MCC:0.379475\n",
      "[8]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.437848\ttest-MCC:0.387523\n",
      "[9]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.446599\ttest-MCC:0.395185\n",
      "[10]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.452787\ttest-MCC:0.39922\n",
      "[11]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.456144\ttest-MCC:0.402682\n",
      "[12]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.460126\ttest-MCC:0.404547\n",
      "[13]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.466253\ttest-MCC:0.407998\n",
      "[14]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.468649\ttest-MCC:0.410289\n",
      "[15]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.471771\ttest-MCC:0.415579\n",
      "[16]\ttrain-error:0.00581\ttest-error:0.005812\ttrain-MCC:0.473664\ttest-MCC:0.41643\n",
      "[17]\ttrain-error:0.005809\ttest-error:0.005812\ttrain-MCC:0.474993\ttest-MCC:0.415371\n",
      "[18]\ttrain-error:0.005795\ttest-error:0.005804\ttrain-MCC:0.475835\ttest-MCC:0.417798\n",
      "[19]\ttrain-error:0.005739\ttest-error:0.005757\ttrain-MCC:0.477735\ttest-MCC:0.416115\n",
      "[20]\ttrain-error:0.005711\ttest-error:0.00574\ttrain-MCC:0.478647\ttest-MCC:0.416231\n",
      "[21]\ttrain-error:0.005658\ttest-error:0.005685\ttrain-MCC:0.48081\ttest-MCC:0.418155\n",
      "[22]\ttrain-error:0.005615\ttest-error:0.005639\ttrain-MCC:0.483121\ttest-MCC:0.420356\n",
      "[23]\ttrain-error:0.005549\ttest-error:0.005571\ttrain-MCC:0.484201\ttest-MCC:0.42242\n",
      "[24]\ttrain-error:0.005489\ttest-error:0.005512\ttrain-MCC:0.485233\ttest-MCC:0.4241\n",
      "[25]\ttrain-error:0.005428\ttest-error:0.005457\ttrain-MCC:0.487261\ttest-MCC:0.424374\n",
      "[26]\ttrain-error:0.005382\ttest-error:0.005428\ttrain-MCC:0.489336\ttest-MCC:0.425618\n",
      "[27]\ttrain-error:0.005337\ttest-error:0.005394\ttrain-MCC:0.490101\ttest-MCC:0.427666\n",
      "[28]\ttrain-error:0.00526\ttest-error:0.005356\ttrain-MCC:0.492269\ttest-MCC:0.428005\n",
      "[29]\ttrain-error:0.005204\ttest-error:0.005314\ttrain-MCC:0.49414\ttest-MCC:0.430322\n",
      "[30]\ttrain-error:0.005157\ttest-error:0.005225\ttrain-MCC:0.495461\ttest-MCC:0.429692\n",
      "[31]\ttrain-error:0.005104\ttest-error:0.005183\ttrain-MCC:0.496715\ttest-MCC:0.4295\n",
      "[32]\ttrain-error:0.005061\ttest-error:0.005157\ttrain-MCC:0.497847\ttest-MCC:0.43179\n",
      "[33]\ttrain-error:0.005034\ttest-error:0.005128\ttrain-MCC:0.500746\ttest-MCC:0.430373\n",
      "[34]\ttrain-error:0.005011\ttest-error:0.005102\ttrain-MCC:0.501783\ttest-MCC:0.430971\n",
      "[35]\ttrain-error:0.004976\ttest-error:0.005094\ttrain-MCC:0.502338\ttest-MCC:0.43179\n",
      "[36]\ttrain-error:0.004964\ttest-error:0.005086\ttrain-MCC:0.505183\ttest-MCC:0.429553\n",
      "[37]\ttrain-error:0.004945\ttest-error:0.00509\ttrain-MCC:0.506582\ttest-MCC:0.430644\n",
      "[38]\ttrain-error:0.004932\ttest-error:0.005094\ttrain-MCC:0.507674\ttest-MCC:0.430642\n",
      "[39]\ttrain-error:0.004913\ttest-error:0.005077\ttrain-MCC:0.509831\ttest-MCC:0.431167\n",
      "[40]\ttrain-error:0.004899\ttest-error:0.005069\ttrain-MCC:0.510589\ttest-MCC:0.430184\n",
      "[41]\ttrain-error:0.004872\ttest-error:0.005056\ttrain-MCC:0.512308\ttest-MCC:0.43013\n",
      "[42]\ttrain-error:0.004855\ttest-error:0.005035\ttrain-MCC:0.514208\ttest-MCC:0.431577\n",
      "[43]\ttrain-error:0.00483\ttest-error:0.005035\ttrain-MCC:0.515348\ttest-MCC:0.431196\n",
      "[44]\ttrain-error:0.004809\ttest-error:0.005014\ttrain-MCC:0.517472\ttest-MCC:0.432561\n",
      "[45]\ttrain-error:0.004801\ttest-error:0.005005\ttrain-MCC:0.517411\ttest-MCC:0.434152\n",
      "[46]\ttrain-error:0.00478\ttest-error:0.005001\ttrain-MCC:0.518439\ttest-MCC:0.434946\n",
      "[47]\ttrain-error:0.004771\ttest-error:0.00498\ttrain-MCC:0.520761\ttest-MCC:0.435848\n",
      "[48]\ttrain-error:0.004762\ttest-error:0.00498\ttrain-MCC:0.521876\ttest-MCC:0.435923\n",
      "[49]\ttrain-error:0.004758\ttest-error:0.004971\ttrain-MCC:0.523326\ttest-MCC:0.436212\n",
      "[50]\ttrain-error:0.004737\ttest-error:0.004959\ttrain-MCC:0.525269\ttest-MCC:0.435634\n",
      "[51]\ttrain-error:0.004727\ttest-error:0.004955\ttrain-MCC:0.527398\ttest-MCC:0.436134\n",
      "[52]\ttrain-error:0.004714\ttest-error:0.004942\ttrain-MCC:0.530651\ttest-MCC:0.435505\n",
      "[53]\ttrain-error:0.004706\ttest-error:0.00495\ttrain-MCC:0.533696\ttest-MCC:0.437539\n",
      "[54]\ttrain-error:0.004689\ttest-error:0.004938\ttrain-MCC:0.535325\ttest-MCC:0.439123\n",
      "[55]\ttrain-error:0.00468\ttest-error:0.004912\ttrain-MCC:0.538966\ttest-MCC:0.437802\n",
      "[56]\ttrain-error:0.004659\ttest-error:0.0049\ttrain-MCC:0.540032\ttest-MCC:0.438594\n",
      "[57]\ttrain-error:0.004638\ttest-error:0.004874\ttrain-MCC:0.543649\ttest-MCC:0.438088\n",
      "[58]\ttrain-error:0.004629\ttest-error:0.004883\ttrain-MCC:0.545275\ttest-MCC:0.437275\n",
      "[59]\ttrain-error:0.004618\ttest-error:0.004879\ttrain-MCC:0.54715\ttest-MCC:0.437543\n",
      "[60]\ttrain-error:0.004607\ttest-error:0.004879\ttrain-MCC:0.55051\ttest-MCC:0.435774\n",
      "[61]\ttrain-error:0.00459\ttest-error:0.004879\ttrain-MCC:0.551944\ttest-MCC:0.436482\n",
      "[62]\ttrain-error:0.00458\ttest-error:0.004874\ttrain-MCC:0.554718\ttest-MCC:0.43675\n",
      "[63]\ttrain-error:0.004569\ttest-error:0.004857\ttrain-MCC:0.555493\ttest-MCC:0.436499\n",
      "[64]\ttrain-error:0.004551\ttest-error:0.004857\ttrain-MCC:0.559451\ttest-MCC:0.437811\n",
      "[65]\ttrain-error:0.004544\ttest-error:0.004853\ttrain-MCC:0.560987\ttest-MCC:0.436254\n",
      "[66]\ttrain-error:0.004536\ttest-error:0.004857\ttrain-MCC:0.563187\ttest-MCC:0.435774\n",
      "[67]\ttrain-error:0.004529\ttest-error:0.004853\ttrain-MCC:0.566382\ttest-MCC:0.436329\n",
      "[68]\ttrain-error:0.004521\ttest-error:0.004841\ttrain-MCC:0.567504\ttest-MCC:0.436491\n",
      "[69]\ttrain-error:0.00451\ttest-error:0.004832\ttrain-MCC:0.568108\ttest-MCC:0.436491\n",
      "[70]\ttrain-error:0.004508\ttest-error:0.004832\ttrain-MCC:0.57028\ttest-MCC:0.435686\n",
      "[71]\ttrain-error:0.004505\ttest-error:0.004824\ttrain-MCC:0.572277\ttest-MCC:0.435222\n",
      "[72]\ttrain-error:0.004499\ttest-error:0.004819\ttrain-MCC:0.575541\ttest-MCC:0.436491\n",
      "[73]\ttrain-error:0.004497\ttest-error:0.004815\ttrain-MCC:0.576818\ttest-MCC:0.436727\n",
      "[74]\ttrain-error:0.004492\ttest-error:0.004815\ttrain-MCC:0.578516\ttest-MCC:0.437406\n",
      "[75]\ttrain-error:0.004482\ttest-error:0.004811\ttrain-MCC:0.581344\ttest-MCC:0.435774\n",
      "[76]\ttrain-error:0.004474\ttest-error:0.004815\ttrain-MCC:0.583749\ttest-MCC:0.435426\n",
      "[77]\ttrain-error:0.004468\ttest-error:0.004803\ttrain-MCC:0.585307\ttest-MCC:0.436161\n",
      "[78]\ttrain-error:0.00446\ttest-error:0.004803\ttrain-MCC:0.587881\ttest-MCC:0.436215\n",
      "[79]\ttrain-error:0.004453\ttest-error:0.004807\ttrain-MCC:0.589834\ttest-MCC:0.436254\n",
      "Repeat 0, split 0, test MCC = 0.436, running time = 6.584 min\n",
      "[0]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.284721\ttest-MCC:0.301155\n",
      "[1]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.314831\ttest-MCC:0.32616\n",
      "[2]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.349977\ttest-MCC:0.355342\n",
      "[3]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.367302\ttest-MCC:0.373465\n",
      "[4]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.37429\ttest-MCC:0.382948\n",
      "[5]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.389936\ttest-MCC:0.388946\n",
      "[6]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.408966\ttest-MCC:0.401733\n",
      "[7]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.417705\ttest-MCC:0.409684\n",
      "[8]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.430996\ttest-MCC:0.422026\n",
      "[9]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.435313\ttest-MCC:0.425585\n",
      "[10]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.441609\ttest-MCC:0.430394\n",
      "[11]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.443625\ttest-MCC:0.437928\n",
      "[12]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.447248\ttest-MCC:0.442239\n",
      "[13]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.452023\ttest-MCC:0.44236\n",
      "[14]\ttrain-error:0.005811\ttest-error:0.005812\ttrain-MCC:0.453331\ttest-MCC:0.444396\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "# specify parameters \n",
    "# 'booster':'gbtree'\n",
    "params = {'max_depth':14, 'eta':0.03, 'silent':1, 'objective':'binary:logistic', 'nthread':20,\n",
    "         'lambda':4, 'subsample':0.9, 'min_child_weight':5, 'booster':'gbtree', 'alpha':0,\n",
    "         'base_score':0.0058, 'colsample_bytree':0.6}\n",
    "\n",
    "# 'booster':'dart'\n",
    "# params = {'max_depth':14, 'eta':0.03, 'silent':1, 'objective':'binary:logistic', 'nthread':20,\n",
    "#         'lambda':4, 'subsample':0.9, 'min_child_weight':5, 'booster':'dart', 'alpha':0,\n",
    "#         'base_score':0.0058, 'nthread':20, 'colsample_bytree':0.6, \n",
    "#         'sample_type':'uniform', 'normalize_type':'tree', 'rate_drop':0.1, 'skip_drop':0.2, 'one_drop':True}\n",
    "\n",
    "cv_results, clfs, running_time = cross_val_predict_skf_rm_xgb(params, x_train, y_train, \n",
    "                                                              num_boost_round=80, n_splits=5, \n",
    "                                                              n_repeats=3, random_state=5876967, \n",
    "                                                              verbose_eval=True)\n",
    "\n",
    "results = {'clfs': clfs, 'cv_results': cv_results, 'running_time': running_time}\n",
    "save_pickle(results, 'results_benchmark_7_time_features_cv_1.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_mean = cv_results['train'].mean(axis=1)\n",
    "cv_train_std = cv_results['train'].std(axis=1)\n",
    "cv_test_mean = cv_results['test'].mean(axis=1)\n",
    "cv_test_std = cv_results['test'].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(np.arange(len(cv_train_mean)), cv_train_mean)\n",
    "plt.fill_between(np.arange(len(cv_train_mean)), cv_train_mean-cv_train_std, cv_train_mean+cv_train_std, alpha=0.5)\n",
    "plt.plot(np.arange(len(cv_train_mean)), cv_test_mean)\n",
    "plt.fill_between(np.arange(len(cv_test_mean)), cv_test_mean-cv_test_std, cv_test_mean+cv_test_std, alpha=0.5)\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "params['seed'] = 28537894\n",
    "clf = xgb.train(params, dtrain, num_boost_round=60,\n",
    "               feval=mcc_eval, evals=[(dtrain, 'train')])\n",
    "\n",
    "y_train_pred = clf.predict(dtrain)\n",
    "\n",
    "# Find best threshold \n",
    "thresholds = np.linspace(0.01, 0.99, 400)\n",
    "mcc = np.array([matthews_corrcoef(y_train, y_train_pred>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "\n",
    "print('Optimal MCC = {:.3f}'.format(mcc.max()))\n",
    "print('Optimal threshold = {:.3f}'.format(best_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(x_test)\n",
    "y_test_pred = clf.predict(dtest)\n",
    "y_test_pred_int = (y_test_pred>best_threshold).astype(int)\n",
    "\n",
    "sub = pd.read_csv(\"../../data/sample_submission.csv.zip\", index_col=0)\n",
    "sub[\"Response\"] = y_test_pred_int\n",
    "sub.to_csv(\"15-benchmark_7_submission_1.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only With MeanTimeDiff Features:\n",
    "- LB: `n_estimators=60`: Private MCC = 0.44401, public MCC = 0.43569\n",
    "- CV: `n_estimators=80`: Score mean = 0.448, std = 0.013\n",
    "- CV: `n_estimators=60`: Score mean = 0.445491, std = 0.0133, MCC~[0.43218, 0.45880]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv_test_mean[60]+cv_test_std[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_mean[60]-cv_test_std[60]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
