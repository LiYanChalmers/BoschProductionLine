{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for measuring performance of engineered features and models\n",
    "\n",
    "Prepare data for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/c3se/NOBACKUP/users/lyaa/conda_dir/miniconda/envs/kaggle/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../../bosch_helper')\n",
    "from bosch_helper import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../../data/data.hdf'):\n",
    "\n",
    "    col_train = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, nrows=10)\n",
    "    col_train = {k: np.float32 for k in col_train.columns}\n",
    "    col_train['Id'] = np.int64\n",
    "\n",
    "    col_test = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, nrows=10)\n",
    "    col_test = {k: np.float32 for k in col_test.columns}\n",
    "    col_test['Id'] = np.int64\n",
    "\n",
    "    train = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, dtype=col_train)\n",
    "    test = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, dtype=col_test)\n",
    "    \n",
    "    x = pd.concat((train, test), keys=['train', 'test'])\n",
    "    \n",
    "    del train, test\n",
    "    gc.collect()\n",
    "    \n",
    "    x.to_hdf('../../data/data.hdf', 'numeric', complib='blosc:lz4', complevel=9, format='t')\n",
    "else:\n",
    "    x = pd.read_hdf('../../data/data.hdf', 'numeric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load date data, calculate start time, end time, start station, and end station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flag = True\n",
    "\n",
    "if os.path.exists('../../data/data.hdf'):\n",
    "    u = pd.HDFStore('../../data/data.hdf')\n",
    "    if 'data' in u.keys():\n",
    "        Flag = False\n",
    "\n",
    "if Flag:\n",
    "\n",
    "    col_train = pd.read_csv('../../data/train_date.csv.zip', index_col=0, nrows=10)\n",
    "    col_train = {k: np.float32 for k in col_train.columns}\n",
    "    col_train['Id'] = np.int64\n",
    "\n",
    "    col_test = pd.read_csv('../../data/test_date.csv.zip', index_col=0, nrows=10)\n",
    "    col_test = {k: np.float32 for k in col_test.columns}\n",
    "    col_test['Id'] = np.int64\n",
    "\n",
    "    date_train = pd.read_csv('../../data/train_date.csv.zip', index_col=0, dtype=col_train)\n",
    "    date_test = pd.read_csv('../../data/test_date.csv.zip', index_col=0, dtype=col_test)\n",
    "    \n",
    "    date = pd.concat((date_train, date_test), keys=['train', 'test'])\n",
    "    \n",
    "    del date_train, date_test\n",
    "    gc.collect()\n",
    "    \n",
    "    date.to_hdf('../../data/data.hdf', 'date', complib='blosc:lz4', complevel=9, format='t')\n",
    "else:\n",
    "    date = pd.read_hdf('../../data/data.hdf', 'date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and end stations and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_nonnan(row):\n",
    "    v = np.where(~np.isnan(row))[0]\n",
    "    if len(v)==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(v[0])\n",
    "\n",
    "def find_last_nonnan(row):\n",
    "    v = np.where(~np.isnan(row))[0]\n",
    "    if len(v)==0:\n",
    "        return -1\n",
    "    else:\n",
    "            return int(v[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('time_station_start.hdf'):\n",
    "\n",
    "    date.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in date.columns])\n",
    "    time_station_start = date.groupby(level=1, axis=1).min(axis=1)\n",
    "\n",
    "    time_station_start['station_start'] = time_station_start.apply(find_first_nonnan, axis=1)\n",
    "    time_station_start['station_end'] = time_station_start.apply(find_last_nonnan, axis=1)\n",
    "\n",
    "    tmp = np.around(time_station_start.iloc[:, :-2].min(axis=1)*100)\n",
    "    tmp = tmp.apply(lambda e: int(e) if ~np.isnan(e) else -1)\n",
    "    time_station_start['time_start'] = tmp\n",
    "\n",
    "    tmp = np.around(time_station_start.iloc[:, :-2].max(axis=1)*100)\n",
    "    tmp = tmp.apply(lambda e: int(e) if ~np.isnan(e) else -1)\n",
    "    time_station_start['time_end'] = tmp\n",
    "\n",
    "    time_station_start.drop(time_station_start.columns[:-4], axis=1, inplace=True)\n",
    "    time_station_start.to_hdf('time_station_start.hdf', \n",
    "        'time_station_start', format='table', complib='blosc:lz4', complevel=9)\n",
    "else:\n",
    "    time_station_start = pd.read_hdf('time_station_start.hdf', 'time_station_start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join `time_station_start` with `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sort_index(level='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start.sort_index(level='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('benchmark_8_numeric_features_1.hdf'):\n",
    "    x = x.join(time_station_start)\n",
    "    \n",
    "    del time_station_start\n",
    "    gc.collect()\n",
    "\n",
    "    del date\n",
    "    gc.collect()\n",
    "    \n",
    "    x.sort_values(['station_start', 'time_start', 'Id'], inplace=True)\n",
    "    \n",
    "    x.to_hdf('benchmark_8_numeric_features_1.hdf', 'x', complib='blosc:lz4', comlevel=9, format='t')\n",
    "    \n",
    "else:\n",
    "    x = pd.read_hdf('benchmark_8_numeric_features_1.hdf', 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
