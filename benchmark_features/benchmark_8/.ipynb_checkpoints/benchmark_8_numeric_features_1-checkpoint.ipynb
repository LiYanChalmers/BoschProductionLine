{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for measuring performance of engineered features and models\n",
    "\n",
    "Prepare data for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    try:\n",
    "        mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "        os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sys import getsizeof\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from scipy import fftpack\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(x, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pickle(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "@jit\n",
    "def mcc(tp, tn, fp, fn):\n",
    "    sup = tp * tn - fp * fn\n",
    "    inf = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
    "    if inf==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sup / np.sqrt(inf)\n",
    "\n",
    "@jit\n",
    "def eval_mcc(y_true, y_prob, show=False):\n",
    "    idx = np.argsort(y_prob)\n",
    "    y_true_sort = y_true[idx]\n",
    "    n = y_true.shape[0]\n",
    "    nump = 1.0 * np.sum(y_true) # number of positive\n",
    "    numn = n - nump # number of negative\n",
    "    tp = nump\n",
    "    tn = 0.0\n",
    "    fp = numn\n",
    "    fn = 0.0\n",
    "    best_mcc = 0.0\n",
    "    best_id = -1\n",
    "    prev_proba = -1\n",
    "    best_proba = -1\n",
    "    mccs = np.zeros(n)\n",
    "    new_mcc = 0\n",
    "    for i in range(n):\n",
    "        # all items with idx < i are predicted negative while others are predicted positive\n",
    "        # only evaluate mcc when probability changes\n",
    "        proba = y_prob[idx[i]]\n",
    "        if proba != prev_proba:\n",
    "            prev_proba = proba\n",
    "            new_mcc = mcc(tp, tn, fp, fn)\n",
    "            if new_mcc >= best_mcc:\n",
    "                best_mcc = new_mcc\n",
    "                best_id = i\n",
    "                best_proba = proba\n",
    "        mccs[i] = new_mcc\n",
    "        if y_true_sort[i] == 1:\n",
    "            tp -= 1.0\n",
    "            fn += 1.0\n",
    "        else:\n",
    "            fp -= 1.0\n",
    "            tn += 1.0\n",
    "    if show:\n",
    "        y_pred = (y_prob >= best_proba).astype(int)\n",
    "        score = matthews_corrcoef(y_true, y_pred)\n",
    "        print(score, best_mcc)\n",
    "        plt.plot(mccs)\n",
    "        return best_proba, best_mcc, y_pred\n",
    "    else:\n",
    "        return best_mcc\n",
    "    \n",
    "def mcc_eval(y_prob, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    best_mcc = eval_mcc(y_true, y_prob)\n",
    "    return 'MCC', best_mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_rskf(clf, x_train, y_train, n_splits=3, \n",
    "                           n_repeats=2, random_state=42, verbose=False, early_stopping=10):\n",
    "    '''\n",
    "    Repeated stratified KFold CV, returns predictions for \n",
    "    each repeat and average score.\n",
    "    n_repeats: repetitions of CV\n",
    "    to disable erlay stopping, set early_stopping to None\n",
    "    '''\n",
    "    scores = []\n",
    "    n_trees = []\n",
    "    clfs = []\n",
    "    running_time = []\n",
    "    \n",
    "    rskf = RepeatedStratifiedKFold(n_repeats=n_repeats, n_splits=n_splits, \n",
    "                                   random_state=0)\n",
    "    np.random.seed(random_state)\n",
    "    for n, (train_index, test_index) in enumerate(rskf.split(x_train, y_train)):\n",
    "        print('Round {}'.format(n))\n",
    "        start_time = time.time()\n",
    "        x_train_tmp, x_test_tmp = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "        y_train_tmp, y_test_tmp = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        clf.random_state = np.random.randint(10000000)\n",
    "        \n",
    "        if early_stopping is not None:\n",
    "            clf.fit(x_train_tmp, y_train_tmp, \n",
    "                    eval_set=[(x_test_tmp, y_test_tmp)], \n",
    "                    eval_metric=mcc_eval, early_stopping_rounds=early_stopping,\n",
    "                    verbose=verbose)\n",
    "            scores.append(-clf.best_score)\n",
    "            n_trees.append(clf.best_ntree_limit)\n",
    "        else:\n",
    "            clf.fit(x_train_tmp, y_train_tmp)\n",
    "            scores.append(eval_mcc(y_test_tmp.values, clf.predict_proba(x_test_tmp)[:, 1]))\n",
    "            n_trees.append(clf.n_estimators)\n",
    "        \n",
    "        clfs.append(clf)\n",
    "        running_time.append(time.time()-start_time)\n",
    "        print('Split {}, score = {:.3f}, best_ntree_limit = {}, total time = {:.3f} min'.format(n, scores[n], \n",
    "            n_trees[n], sum(running_time)/60))\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return clfs, scores, n_trees, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_skf_rm(clf, x_train, y_train, n_splits=3, \n",
    "                           n_repeats=2, random_state=42, verbose=False, early_stopping=10):\n",
    "    '''\n",
    "    Stratified KFold CV with repeated models\n",
    "    to disable erlay stopping, set early_stopping to None\n",
    "    '''\n",
    "    scores = []\n",
    "    n_trees = []\n",
    "    clfs = []\n",
    "    running_time = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=0, shuffle=True)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    for m in range(n_repeats):\n",
    "        print('Repeat {}'.format(m))\n",
    "        for n, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "            start_time = time.time()\n",
    "            x_train_tmp, x_test_tmp = x_train.iloc[train_index], x_train.iloc[test_index]\n",
    "            y_train_tmp, y_test_tmp = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "            clf.random_state = np.random.randint(10000000)\n",
    "            # print(clf.random_state)\n",
    "\n",
    "            if early_stopping is not None:\n",
    "                clf.fit(x_train_tmp, y_train_tmp, \n",
    "                        eval_set=[(x_test_tmp, y_test_tmp)], \n",
    "                        eval_metric=mcc_eval, early_stopping_rounds=early_stopping,\n",
    "                        verbose=verbose)\n",
    "                scores.append(-clf.best_score)\n",
    "                n_trees.append(clf.best_ntree_limit)\n",
    "            else:\n",
    "                clf.fit(x_train_tmp, y_train_tmp)\n",
    "                scores.append(eval_mcc(y_test_tmp.values, clf.predict_proba(x_test_tmp)[:, 1]))\n",
    "                n_trees.append(clf.n_estimators)\n",
    "            \n",
    "            clfs.append(clf)\n",
    "            running_time.append(time.time() - start_time)\n",
    "            print('Split {}, score = {:.3f}, n_best_trees = {}, total time = {:.3f} min'.format(n, \n",
    "                scores[m*n_repeats+n], n_trees[m*n_repeats+n], sum(running_time)/60))\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return clfs, scores, n_trees, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict_skf_rm_xgb(params, x_train, y_train, num_boost_round=3, n_splits=3, \n",
    "                           n_repeats=2, random_state=3795264, verbose_eval=False):\n",
    "    '''\n",
    "    Stratified KFold CV with repeated models\n",
    "    Early stopping is totally disabled\n",
    "    Uses xgb.cv API\n",
    "    verbose_eval is the same as in xgb.train\n",
    "    '''\n",
    "    cv_results = {}\n",
    "    clfs = {}\n",
    "    running_time = {}\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=np.random.randint(10**6), shuffle=True)\n",
    "    \n",
    "    for m in range(n_repeats):\n",
    "        for n, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Construct DMatrix\n",
    "            dtrain = xgb.DMatrix(x_train.iloc[train_index], label=y_train.iloc[train_index])\n",
    "            dtest = xgb.DMatrix(x_train.iloc[test_index], label=y_train.iloc[test_index])\n",
    "            \n",
    "            # Placeholder for evals_result\n",
    "            cv_results[m, n] = {}\n",
    "            params['seed'] = np.random.randint(10**6)\n",
    "            clfs[m, n] = xgb.train(params, dtrain, num_boost_round=num_boost_round,\n",
    "                                   evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "                                  feval=mcc_eval, maximize=True, early_stopping_rounds=None, \n",
    "                                  evals_result=cv_results[m, n], verbose_eval=verbose_eval)\n",
    "        \n",
    "            running_time[m, n] = time.time() - start_time\n",
    "            \n",
    "            print('Repeat {}, split {}, test MCC = {:.3f}, running time = {:.3f} min'.format(m, n, \n",
    "                cv_results[m, n]['test']['MCC'][-1], running_time[m, n]/60))\n",
    "        \n",
    "    # Post-process cv_results\n",
    "    cv_results_final = {}\n",
    "    for m in range(n_repeats):\n",
    "        for n in range(n_splits):\n",
    "            cv_results_final['train', m, n] = cv_results[m, n]['train']['MCC']\n",
    "            cv_results_final['test', m, n] = cv_results[m, n]['test']['MCC']\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(cv_results_final)\n",
    "    df.index.name = 'iteration'\n",
    "    df.columns.names = ['dataset', 'repeat', 'split']\n",
    "\n",
    "    print('Score mean = {:.3f}, std = {:.3f}'.format(df['test'].iloc[-1].mean(), df['test'].iloc[-1].std()))\n",
    "    \n",
    "    return df, clfs, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_difference_to_failures(x, failure_max):\n",
    "    '''\n",
    "    Find the average time difference to the last and next failure_max failures.\n",
    "    x should have ['Response', 'time_start', 'time_end']\n",
    "    '''\n",
    "    \n",
    "    u = x[['Response', 'time_start']].copy()\n",
    "    u.columns = ['Response', 'time']\n",
    "    x_start = time_difference_to_failures_helper(u, failure_max, '_start')\n",
    "    \n",
    "    u = x[['Response', 'time_end']].copy()\n",
    "    u.columns = ['Response', 'time']\n",
    "    x_end = time_difference_to_failures_helper(u, failure_max, '_end')\n",
    "    \n",
    "    return x_start.join(x_end)\n",
    "\n",
    "def time_difference_to_failures_helper(x, failure_max, suffix):\n",
    "    '''\n",
    "    Find the mean time difference since last/next 1, 2, ..., failure_max failures\n",
    "    when samples are sorted by the time column\n",
    "    suffix is used for column names of the final results\n",
    "    x is a DataFrame containing:\n",
    "    - Both train and test data\n",
    "    - Two columns: Response and a time column, \n",
    "        which is used to sort samples and calculate time differences\n",
    "    '''\n",
    "    \n",
    "    # sort by time and Id\n",
    "    x.sort_values(['time', 'Id'], inplace=True)\n",
    "    x.Response.fillna(0, inplace=True)\n",
    "    x.Response = x.Response.astype(np.int8)\n",
    "    \n",
    "    # ranking in sorted order\n",
    "    x['rank_sort_time'] = np.arange(1, len(x)+1)\n",
    "    \n",
    "    # rank of failures\n",
    "    x['rank_failure'] = x['Response']\n",
    "    x['rank_failure'] = x['rank_failure'].cumsum()\n",
    "    x.loc[x['Response']!=1, 'rank_failure'] = 0\n",
    "    \n",
    "    # the rank_failure of the 1st previous failure for each sample\n",
    "    # for the first several samples without previous failures, use 0\n",
    "    x['fp1'] = x['rank_failure'].shift().fillna(0).astype(np.int64)\n",
    "    x['fp1'] = x['fp1'].cummax()\n",
    "    x['fp1'] = x['fp1'].astype(np.int64)\n",
    "    \n",
    "    # the failure rank of the 2nd to failure_max previous failure for each sample\n",
    "    failure_list = np.arange(2, failure_max+1)\n",
    "    for f in failure_list:\n",
    "        x['fp'+str(f)] = x['fp'+str(f-1)]-1\n",
    "        x.loc[x['fp'+str(f)]<0, 'fp'+str(f)] = 0\n",
    "        x['fp'+str(f)] = x['fp'+str(f)].astype(np.int64)\n",
    "        \n",
    "    # the failure rank of the 1st next failure for each sample\n",
    "    # for the last several samples do not have next failure, use failure_count+1\n",
    "    failure_count = sum(x['Response'])\n",
    "    x['fn1'] = x['fp1'].shift(-1).fillna(failure_count)+1\n",
    "    # the total number of failures\n",
    "    # assign np.nan to rows whose rank_failure is larger than failure_count\n",
    "    x.loc[x['fn1']>failure_count, 'fn1'] = failure_count+1\n",
    "    x['fn1'] = x['fn1'].astype(np.int64)\n",
    "\n",
    "    # the failure rank of the 2nd to failure_max (failure_max=10 here) next failure for each sample\n",
    "    for f in failure_list:\n",
    "        x['fn'+str(f)] = x['fn'+str(f-1)]+1\n",
    "        x.loc[x['fn'+str(f)]>failure_count, 'fn'+str(f)] = failure_count+1\n",
    "        x['fn'+str(f)] = x['fn'+str(f)].astype(np.int64)\n",
    "        \n",
    "    # a mapping from failure rank to start time of the failure\n",
    "    rank_failure_to_time = x.loc[x['rank_failure']!=0, ['rank_failure', 'time']].set_index(\n",
    "        'rank_failure', drop=True, inplace=False)\n",
    "    rank_failure_to_time = rank_failure_to_time.to_dict()\n",
    "    rank_failure_to_time = rank_failure_to_time['time']\n",
    "    rank_failure_to_time[0] = np.nan\n",
    "    rank_failure_to_time[failure_count+1] = np.nan\n",
    "    \n",
    "    # map from failure rank to time of the failure \n",
    "    for f in range(1, failure_max+1):\n",
    "        x['fp{}_time'.format(f)] = x['fp'+str(f)].map(rank_failure_to_time)\n",
    "        \n",
    "    # map from failure rank to time of the failure \n",
    "    for f in range(1, failure_max+1):\n",
    "        x['fn{}_time'.format(f)] = x['fn'+str(f)].map(rank_failure_to_time)\n",
    "        \n",
    "    # Calculate average of the next n failures\n",
    "    ave_list = []\n",
    "    for f in range(1, failure_max+1):\n",
    "        ave_list.append('fn{}_time'.format(f))\n",
    "        x['fn{}_time_ave{}'.format(f, suffix)] = x[ave_list].mean(axis=1) - x['time']\n",
    "\n",
    "    # Calculate average of the previous n failures\n",
    "    ave_list = []\n",
    "    for f in range(1, failure_max+1):\n",
    "        ave_list.append('fp{}_time'.format(f))\n",
    "        x['fp{}_time_ave{}'.format(f, suffix)] = x[ave_list].mean(axis=1) - x['time']\n",
    "        \n",
    "    # drop auxiliary columns\n",
    "    drop_list = [k for i in range(1, failure_max+1) for k in ['fp'+str(i), 'fn'+str(i)]]\n",
    "    drop_list.extend([k for f in range(1, failure_max+1) for k in ['fp'+str(f)+'_time', 'fn'+str(f)+'_time']])\n",
    "    drop_list.extend(['time', 'rank_sort_time', 'rank_failure', 'Response'])\n",
    "    x.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    # sort index\n",
    "    x.sort_index(by='Id', axis=0, inplace=True)    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, nrows=10)\n",
    "col_train = {k: np.float16 for k in col_train.columns}\n",
    "col_train['Id'] = np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_test = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, nrows=10)\n",
    "col_test = {k: np.float16 for k in col_test.columns}\n",
    "col_test['Id'] = np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/train_numeric.csv.zip', index_col=0, dtype=col_train)\n",
    "test = pd.read_csv('../../data/test_numeric.csv.zip', index_col=0, dtype=col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.concat((train, test), keys=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_hdf('../../data/data.hdf', 'numeric', complib='blosc:lz4', complevel=9, format='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load date data, calculate start time, end time, start station, and end station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_train = pd.read_csv('../../data/train_date.csv.zip', index_col=0, nrows=10)\n",
    "col_train = {k: np.float16 for k in col_train.columns}\n",
    "col_train['Id'] = np.int64\n",
    "\n",
    "col_test = pd.read_csv('../../data/test_date.csv.zip', index_col=0, nrows=10)\n",
    "col_test = {k: np.float16 for k in col_test.columns}\n",
    "col_test['Id'] = np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = pd.read_csv('../../data/train_date.csv.zip', index_col=0, dtype=col_train)\n",
    "date_test = pd.read_csv('../../data/test_date.csv.zip', index_col=0, dtype=col_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.concat((date_train, date_test), keys=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del date_train, date_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.to_hdf('../../data/data.hdf', 'date', complib='blosc:lz4', complevel=9, format='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time station start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in date.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start = date.groupby(level=1, axis=1).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_nonnan(row):\n",
    "    v = np.where(~np.isnan(row))[0]\n",
    "    if len(v)==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start['station_start'] = time_station_start.apply(find_first_nonnan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_last_nonnan(row):\n",
    "    v = np.where(~np.isnan(row))[0]\n",
    "    if len(v)==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return v[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start['station_end'] = time_station_start.apply(find_last_nonnan, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_station_start['station_start'] = time_station_start['station_start'].astype('category')\n",
    "# time_station_start['station_end'] = time_station_start['station_end'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start['time_start'] = time_station_start.iloc[:, :-2].min(axis=1)\n",
    "time_station_start['time_end'] = time_station_start.iloc[:, :-2].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start.drop(time_station_start.columns[:-4], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>station_start</th>\n",
       "      <th>station_end</th>\n",
       "      <th>time_start</th>\n",
       "      <th>time_end</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">train</th>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>82.25</td>\n",
       "      <td>87.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1313.00</td>\n",
       "      <td>1316.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1619.00</td>\n",
       "      <td>1624.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1149.00</td>\n",
       "      <td>1154.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>602.50</td>\n",
       "      <td>606.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          station_start  station_end  time_start   time_end\n",
       "      Id                                                   \n",
       "train 4             0.0         52.0       82.25    87.3125\n",
       "      6             4.0         52.0     1313.00  1316.0000\n",
       "      7             0.0         52.0     1619.00  1624.0000\n",
       "      9             0.0         52.0     1149.00  1154.0000\n",
       "      11            0.0         52.0      602.50   606.0000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_station_start.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start.columns = ['station_start', 'station_end', 'time_start', 'time_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_station_start = time_station_start.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join `time_station_start` with `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.join(time_station_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del time_station_start\n",
    "gc.collect()\n",
    "\n",
    "del date\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sort_values(['station_start', 'time_start', 'Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_hdf('numeric_all.hdf', 'x', complib='blocs:lz4', comlevel=9, format='t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
