{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li/miniconda3/envs/kaggle/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If RAM is limited, set total_rows = 10000 or 100000; otherwise, set total_rows = None\n",
    "total_rows = None\n",
    "date = pd.read_csv('data/train_date.csv.zip', index_col=0, nrows=total_rows)\n",
    "\n",
    "# Drop rows and columns if they are redundant\n",
    "date.dropna(axis=0, how='all', inplace=True)\n",
    "date.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Load labels\n",
    "response = pd.read_csv('data/train_numeric.csv.zip', index_col=0, \n",
    "                       usecols=[0, 969], nrows=total_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restructure columns\n",
    "Each column of `date` records a time stamp in the production line and tracks flows of parts. The columns follow a name convention of `Line_Station_Feature`. \n",
    "\n",
    "The structure of production line, station, and feature is hierarchical, i.e., there is no feature belongs to two stations, and no station belongs to two lines. So we can restructure the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station and feature names, and build a new pandas MultiIndex object\n",
    "new_columns = pd.MultiIndex.from_tuples([tuple([int(a[1:]) \n",
    "                                          for a in x[3:].split('_')])\n",
    "                                          for x in date.columns], \n",
    "                                          names=['station', 'feature'])\n",
    "date.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract station names\n",
    "stations = sorted([x for x in date.columns.levels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The earliest recorded time of a part going into a station\n",
    "# Notice that now we have dropped features (recorded time stamps) and only cares about stations\n",
    "date_station0 = pd.DataFrame({i: date[i].apply(min, axis=1) \n",
    "                            for i in stations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two series recording if a part is positive (failure) or negative (not failure)\n",
    "response_p = response.Response.apply(lambda x: 'p' if x==1 else np.nan)\n",
    "response_n = response.Response.apply(lambda x: 'n' if x==0 else np.nan)\n",
    "\n",
    "# Add the two series into `date_station0`\n",
    "date_station0['p'] = response_p\n",
    "date_station0['n'] = response_n\n",
    "\n",
    "# Obtain indexes of positive and negative\n",
    "neg_idx = date_station0[date_station0.n=='n'].index\n",
    "pos_idx = date_station0[date_station0.p=='p'].index\n",
    "\n",
    "# Calculate positive probabilities of each station\n",
    "# We add two dummy stations into `node_weights` representing the positive and negative labels\n",
    "node_weights = date_station0[date_station0.p=='p'].notna().sum(axis=0)/date_station0.notna().sum(axis=0)\n",
    "node_weights = node_weights.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the flow of stations for each part by dropping NaNs in each row of `date_station0` \n",
    "# `date_station` is a pandas series containing the list of stations, including positive and negative labels\n",
    "date_station = date_station0.apply(lambda x: x.dropna().index.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert station flows to lists of station transitions for each part\n",
    "date_station_list = date_station.apply(lambda x: [(x[i], x[i+1]) for i in range(len(x)-1)]).values.tolist()\n",
    "# Obtain station transitions for positive samples\n",
    "date_station_list_pos = date_station.loc[pos_idx].apply(lambda x: [(x[i], x[i+1]) for i in range(len(x)-1)]).values.tolist()\n",
    "# Obtain station transitions for negative samples\n",
    "date_station_list_neg = date_station.loc[neg_idx].apply(lambda x: [(x[i], x[i+1]) for i in range(len(x)-1)]).values.tolist()\n",
    "\n",
    "# convert list of lists to one list, and then to series \n",
    "date_station_list = [x for a in date_station_list for x in a]\n",
    "date_station_list_pos = [x for a in date_station_list_pos for x in a]\n",
    "date_station_list_neg = [x for a in date_station_list_neg for x in a]\n",
    "\n",
    "date_station_list = pd.Series(date_station_list)\n",
    "date_station_list_pos = pd.Series(date_station_list_pos)\n",
    "date_station_list_neg = pd.Series(date_station_list_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate value counts (histogram) of each transition\n",
    "edges = date_station_list.value_counts().to_dict()\n",
    "edges_pos = date_station_list_pos.value_counts().to_dict()\n",
    "edges_neg = date_station_list_neg.value_counts().to_dict()\n",
    "\n",
    "# Calculate positive (failure) rate for each transition\n",
    "edges_pos_rate = {k: edges_pos[k]/edges[k] for k in edges_pos.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also include the dummy positive and negative stations into the station list\n",
    "stations.extend(['n', 'p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check orders of station flows\n",
    "All parts flow from low-number stations to high-number stations, no exceptions found.\n",
    "Actually, this part is not correct, because the staion flows are arranged by station number at the begining, not by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "station_flows = [] # a list containing all station flows as lists, the last station is a dummy station 'n' or 'p'\n",
    "reverse_flows = []\n",
    "for x in date_station:\n",
    "    if x not in station_flows:\n",
    "        station_flows.append(x)\n",
    "        x_now = x[0]\n",
    "        for i in range(1, len(x)-1):\n",
    "            x_next = x[i]\n",
    "            if x_next < x_now:\n",
    "                reverse_flows.append(x)\n",
    "                break\n",
    "            else:\n",
    "                x_now = x_next\n",
    "                \n",
    "print(len(reverse_flows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics of station flows\n",
    "The counts, error counts, and error rates of station flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_1_2_4_7_8_11_29_30_31_33_34_35_37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12_13_14_16_18_20_21_29_30_33_34_35_37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0_1_2_5_6_8_10_29_30_33_34_35_37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0_1_2_4_7_8_10_29_30_33_34_36_37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0_1_3_4_7_8_11_29_30_33_34_36_37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      flow  response\n",
       "4      0_1_2_4_7_8_11_29_30_31_33_34_35_37         0\n",
       "6   12_13_14_16_18_20_21_29_30_33_34_35_37         0\n",
       "7         0_1_2_5_6_8_10_29_30_33_34_35_37         0\n",
       "9         0_1_2_4_7_8_10_29_30_33_34_36_37         0\n",
       "11        0_1_3_4_7_8_11_29_30_33_34_36_37         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dateframe containing string flow and response\n",
    "# I will use it to calculate error rate of flows\n",
    "date_station_str = {}\n",
    "for i in date_station.index:\n",
    "    tmp = date_station[i]\n",
    "    tmp = [str(x) for x in tmp]\n",
    "    date_station_str[i] = '_'.join(tmp)\n",
    "date_station_str = pd.Series(date_station_str)\n",
    "\n",
    "date_station_str = pd.DataFrame(date_station_str)\n",
    "date_station_str['response'] = date_station_str[0].apply(lambda x: 0 if x.split('_')[-1]=='n' else 1)\n",
    "date_station_str[0] = date_station_str[0].apply(lambda x: x[:-2])\n",
    "date_station_str.columns = ['flow', 'response']\n",
    "\n",
    "date_station_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_station_flow_stat = \\\n",
    "    date_station_str.groupby('flow', sort=False).agg([np.sum, np.mean, 'count']).sort_values(\n",
    "    by=[('response', 'sum'), ('response', 'mean'), ('response', 'count')], ascending=[False, False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(x, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pickle(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save station error probability\n",
    "filename = 'station_error_rate.pickle'\n",
    "save_pickle(node_weights, filename)\n",
    "\n",
    "filename = 'station_transition_error_rate_{}.pickle'.format(total_rows)\n",
    "save_pickle(edges_pos_rate, filename)\n",
    "\n",
    "filename = 'station_transition_error_count_{}.pickle'.format(total_rows)\n",
    "save_pickle(edges_pos, filename)\n",
    "\n",
    "date_station_flow_stat.to_csv('station_flow_error_stat_{}.csv'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save station error statistics\n",
    "total_samples = date_station0.notna().sum(axis=0).to_dict()\n",
    "total_pos = date_station0[date_station0.p=='p'].notna().sum(axis=0).to_dict()\n",
    "\n",
    "station_stat = {k: [node_weights[k], total_pos[k], total_samples[k]/1183747, total_samples[k]] \n",
    "                for k in node_weights.keys()}\n",
    "\n",
    "station_stat = pd.DataFrame.from_dict(station_stat, orient='index')\n",
    "station_stat.columns = ['error_rate', 'error_count', 'sample_rate', 'sample_count']\n",
    "station_stat.index.name = 'station'\n",
    "\n",
    "station_stat.to_csv('station_stat_{}.csv'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save transition error statistics\n",
    "edges_stat = {k: [edges[k], edges_pos[k], edges_pos_rate[k]] for k in edges_pos.keys()}\n",
    "edges_stat = pd.DataFrame.from_dict(edges_stat, orient='index')\n",
    "edges_stat.columns = ['sample_count', 'error_count', 'error_rate']\n",
    "edges_stat.index.name = 'transition'\n",
    "edges_stat.to_csv('transition_stat_{}.csv'.format(total_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for plotting\n",
    "\n",
    "# station names\n",
    "filename = 'stations_{}.pickle'.format(total_rows)\n",
    "save_pickle(stations, filename)\n",
    "\n",
    "# edges\n",
    "filename = 'edges_{}.pickle'.format(total_rows)\n",
    "save_pickle(edges, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Use `networkx` to create a weighted directed graph, whose nodes and edges represent stations and station transitions, respectively. Node and edge weights are the corresponding positive rates.\n",
    "\n",
    "Use `Plotly` to create figures for interactive visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "stations = read_pickle('stations_None.pickle')\n",
    "edges = read_pickle('edges_None.pickle')\n",
    "node_weights = read_pickle('station_error_rate.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph with `networkx`\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(stations)\n",
    "G.add_edges_from(edges.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign positions to each network node according to work flows.\n",
    "# Manual adjustment is required here for good visualization.\n",
    "\n",
    "# Initially, use spring layout of node positions, but not necessary later.\n",
    "pos = nx.spring_layout(G)\n",
    "for n, p in pos.items():\n",
    "    G.node[n]['pos'] = p\n",
    "    \n",
    "G.node[0]['pos'] = [0, 1]\n",
    "G.node[1]['pos'] = [1, 1]\n",
    "G.node[2]['pos'] = [2, 2]\n",
    "G.node[3]['pos'] = [2, 0]\n",
    "G.node[4]['pos'] = [3, 2]\n",
    "G.node[5]['pos'] = [3, 0]\n",
    "G.node[6]['pos'] = [4, 2]\n",
    "G.node[7]['pos'] = [4, 0]\n",
    "G.node[8]['pos'] = [5, 1]\n",
    "G.node[9]['pos'] = [6, 2.5]\n",
    "G.node[10]['pos'] = [6, 1]\n",
    "G.node[11]['pos'] = [6, -0.5]\n",
    "\n",
    "G.node[12]['pos'] = [0, -3]\n",
    "G.node[13]['pos'] = [1, -3]\n",
    "G.node[14]['pos'] = [2, -2]\n",
    "G.node[15]['pos'] = [2, -4]\n",
    "G.node[16]['pos'] = [3, -2]\n",
    "G.node[17]['pos'] = [3, -4]\n",
    "G.node[18]['pos'] = [4, -2]\n",
    "G.node[19]['pos'] = [4, -4]\n",
    "G.node[20]['pos'] = [5, -3]\n",
    "G.node[21]['pos'] = [6, -1.5]\n",
    "G.node[22]['pos'] = [6, -3]\n",
    "G.node[23]['pos'] = [6, -4.5]\n",
    "\n",
    "G.node[24]['pos'] = [5, -6]\n",
    "G.node[25]['pos'] = [5, -7]\n",
    "G.node[26]['pos'] = [7, -6]\n",
    "G.node[27]['pos'] = [7, -7]\n",
    "G.node[28]['pos'] = [7, -8]\n",
    "\n",
    "\n",
    "G.node[29]['pos'] = [8, -1]\n",
    "G.node[30]['pos'] = [9, -1]\n",
    "G.node[31]['pos'] = [10, -2.5]\n",
    "G.node[32]['pos'] = [11, 0]\n",
    "G.node[33]['pos'] = [11, -2]\n",
    "G.node[34]['pos'] = [12, -2]\n",
    "G.node[35]['pos'] = [13, 0]\n",
    "G.node[36]['pos'] = [13, -2]\n",
    "G.node[37]['pos'] = [14, -1]\n",
    "G.node[38]['pos'] = [15, -1]\n",
    "\n",
    "G.node[39]['pos'] = [8, -4]\n",
    "G.node[40]['pos'] = [9, -4]\n",
    "G.node[41]['pos'] = [10, -4]\n",
    "G.node[42]['pos'] = [10, -5]\n",
    "G.node[43]['pos'] = [11, -3]\n",
    "G.node[44]['pos'] = [11, -5]\n",
    "G.node[45]['pos'] = [12, -4]\n",
    "G.node[46]['pos'] = [12, -5]\n",
    "G.node[47]['pos'] = [13, -4]\n",
    "G.node[48]['pos'] = [14, -4]\n",
    "G.node[49]['pos'] = [15, -3]\n",
    "G.node[50]['pos'] = [15, -5]\n",
    "G.node[51]['pos'] = [16, -4]\n",
    "\n",
    "G.node['n']['pos'] = [18, 1]\n",
    "G.node['p']['pos'] = [18, -4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces for plotly figure illustrating work flows\n",
    "edge_trace = go.Scatter(\n",
    "    x=[],\n",
    "    y=[],\n",
    "    text=[],\n",
    "    line=dict(width=1,color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "for edge in G.edges():\n",
    "    x0, y0 = G.node[edge[0]]['pos']\n",
    "    x1, y1 = G.node[edge[1]]['pos']\n",
    "    edge_trace['x'] += [x0, x1, None]\n",
    "    edge_trace['y'] += [y0, y1, None]\n",
    "    edge_trace['text'].append(edges[edge]/station_stat['sample_count'].iloc[-2:].sum())\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "x=[],\n",
    "y=[],\n",
    "text=[],\n",
    "hovertext=[],\n",
    "mode='markers+text',\n",
    "hoverinfo='hovertext',\n",
    "textposition='bottom',\n",
    "marker=dict(\n",
    "    showscale=False,\n",
    "    # colorscale options\n",
    "    # 'Greys' | 'Greens' | 'Bluered' | 'Hot' | 'Picnic' | 'Portland' |\n",
    "    # Jet' | 'RdBu' | 'Blackbody' | 'Earth' | 'Electric' | 'YIOrRd' | 'YIGnBu'\n",
    "    colorscale='YIGnBu',\n",
    "    reversescale=True,\n",
    "    color=[],\n",
    "    size=10,\n",
    "#     colorbar=dict(\n",
    "#         thickness=15,\n",
    "#         title='Node Connections',\n",
    "#         xanchor='left',\n",
    "#         titleside='right'\n",
    "#     ),\n",
    "    line=dict(width=2)))\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = G.node[node]['pos']\n",
    "    node_trace['x'].append(x)\n",
    "    node_trace['y'].append(y)\n",
    "    node_trace['text'].append(node)\n",
    "    node_trace['hovertext'].append(node_weights[node])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~lygirona/96.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the figure\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>Bosch Production Line',\n",
    "                titlefont=dict(size=16),\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "\n",
    "py.iplot(fig, filename='networkx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~lygirona/120.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error probabilities of stations\n",
    "trace1 = go.Scatter(\n",
    "    x = list(node_weights.keys())[:-2],\n",
    "    y = list(node_weights.values())[:-2],\n",
    "    name='Error Probability'\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x = list(node_weights.keys())[:-2],\n",
    "    y = np.median(list(node_weights.values())[:-2])*np.ones(52),\n",
    "    name='Median Error Probability'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2],\n",
    "                layout=go.Layout(title='Error Probability',\n",
    "                                xaxis=dict(title='Station', range=[-1, 52]),\n",
    "                                yaxis=dict(title='Probability', range=[0, 0.05])))\n",
    "\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~lygirona/122.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error probabilities of station transitions\n",
    "edges_pos_rate_sorted = sorted(edges_pos_rate.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "trace_pos_rate = go.Scatter(\n",
    "    x = [],\n",
    "    y = [], \n",
    "    mode='lines',\n",
    "    hovertext=[],\n",
    "    hoverinfo='hovertext'\n",
    ")\n",
    "\n",
    "for n, x in enumerate(edges_pos_rate_sorted):\n",
    "    if n>2:\n",
    "        trace_pos_rate['x'].append(n)\n",
    "        trace_pos_rate['y'].append(x[1])\n",
    "        trace_pos_rate['hovertext'].append(x[0].__str__())\n",
    "        \n",
    "# Absolute error numbers of station transitions\n",
    "edges_pos_sorted = sorted(edges_pos.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "trace_pos_count = go.Scatter(\n",
    "    x = [],\n",
    "    y = [], \n",
    "    mode='lines',\n",
    "    hovertext=[],\n",
    "    hoverinfo='hovertext',\n",
    "    yaxis='y2'\n",
    ")\n",
    "\n",
    "for n, x in enumerate(edges_pos_sorted):\n",
    "    if n>2:\n",
    "        trace_pos_count['x'].append(n)\n",
    "        trace_pos_count['y'].append(x[1])\n",
    "        trace_pos_count['hovertext'].append(x[0].__str__())\n",
    "        \n",
    "fig = go.Figure(data=[trace_pos_rate, trace_pos_count], \n",
    "                layout=go.Layout(\n",
    "                legend=dict(orientation=\"h\"),\n",
    "                title='<br>Transition Error Probability',\n",
    "                xaxis=dict(range=[0, len(edges_pos_rate_sorted)+5], title='Transition Index'),\n",
    "                yaxis=dict(range=[0, 0.6], title='Probability', showgrid=False),\n",
    "                yaxis2=dict(range=[0, edges_pos_sorted[0][1]+10], title='Count',\n",
    "                           overlaying='y', side='right', showgrid=False, showline=True)\n",
    "                ))\n",
    "        \n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183165"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amount of data used in visualization\n",
    "# More data will be more accurate, and results may change as well.\n",
    "len(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~lygirona/124.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_pos_sorted = sorted(edges_pos.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "trace_pos_rate = go.Scatter(\n",
    "    x = [],\n",
    "    y = [], \n",
    "    mode='lines',\n",
    "    hovertext=[],\n",
    "    hoverinfo='hovertext'\n",
    ")\n",
    "\n",
    "for n, x in enumerate(edges_pos_sorted):\n",
    "    if n>2:\n",
    "        trace_pos_rate['x'].append(n)\n",
    "        trace_pos_rate['y'].append(x[1])\n",
    "        trace_pos_rate['hovertext'].append(x[0].__str__())\n",
    "        \n",
    "fig = go.Figure(data=[trace_pos_rate], \n",
    "                layout=go.Layout(\n",
    "                title='<br>Transition Error Probability',\n",
    "                xaxis=dict(range=[0, len(edges_pos_sorted)+5], title='Transition Index'),\n",
    "                yaxis=dict(range=[0, edges_pos_sorted[0][1]+10], title='Probability')\n",
    "                ))\n",
    "        \n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_pos_combine = {k: (edges_pos[k], edges_pos_rate[k]) for k in edges_pos.keys()}\n",
    "edges_name, edges_value = zip(*edges_pos_combine.items())\n",
    "edges_name = list(edges_name)\n",
    "edges_value = list(edges_value)\n",
    "x, y = zip(*edges_value)\n",
    "x, y = list(x), list(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
