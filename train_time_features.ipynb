{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.name=='nt':\n",
    "    mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-8.1.0-posix-seh-rt_v6-rev0\\\\mingw64\\\\bin'\n",
    "    os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sys import getsizeof\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_pickle(x, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(x, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pickle(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        x = pickle.load(handle)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "def bayesian_time_diff(x_train, x_test, suffix, shift, feat):\n",
    "    '''\n",
    "    Calculate bayesian mean time difference between neighboring failures.\n",
    "    shift=n, n>0: n next failures\n",
    "    shift=n, n<0: n previous failures\n",
    "    x_train: has Response column\n",
    "    x_test: does not have Response column, other columns should be the same as x_train\n",
    "    feat: feature used for sorting and calculating distance\n",
    "    '''\n",
    "    assert(shift!=0), 'shift cannot equal 0!'\n",
    "    \n",
    "    # calculate 1st distance\n",
    "    x = pd.concat([x_train, x_test]).fillna(0)\n",
    "    x['idx'] = np.arange(len(x), dtype=np.int32)\n",
    "    n_train = len(x_train)\n",
    "    x['Response'] = x['Response'].astype(int)\n",
    "    x.sort_values(feat, axis=0, inplace=True)\n",
    "    \n",
    "    x['res1'] = x['Response']\n",
    "    x.loc[x['Response']==1, 'res1'] = x.loc[x['Response']==1, feat]\n",
    "    if shift<0:\n",
    "        x['res1'] = x[feat] - x['res1'].shift(1).fillna(0).replace(0, method='ffill')\n",
    "    elif shift>0:\n",
    "        x['res1'] = x['res1'].shift(-1).fillna(9999).replace(0, method='bfill') - x[feat]\n",
    "        \n",
    "    shift_abs = np.abs(shift)\n",
    "    if shift_abs>1:\n",
    "        for n in range(2, shift_abs+1):\n",
    "            x['res'+str(n)] = x['Response']\n",
    "            x.loc[x['Response']==1, 'res'+str(n)] = x.loc[x['Response']==1, 'res'+str(n-1)]\n",
    "            if shift<0:\n",
    "                x['res'+str(n)] = x['res'+str(n)].shift(1).fillna(0).replace(0, method='ffill') + x['res'+str(n-1)]\n",
    "            elif shift>0:\n",
    "                x['res'+str(n)] = x['res'+str(n)].shift(-1).fillna(9999).replace(0, method='bfill') + x['res'+str(n-1)]\n",
    "\n",
    "    x[feat+suffix] = x[['res'+str(n) for n in range(1, shift_abs+1)]].mean(axis=1)\n",
    "    x.drop(['res'+str(n) for n in range(1, shift_abs+1)], axis=1, inplace=True)\n",
    "    x.sort_values('idx', axis=0, inplace=True)\n",
    "    x.drop('idx', axis=1, inplace=True)\n",
    "    x_train0 = x.iloc[:n_train]\n",
    "    x_test0 = x.iloc[n_train:]\n",
    "    x_test0.drop('Response', axis=1, inplace=True)\n",
    "    \n",
    "    return x_train0, x_test0\n",
    "\n",
    "\n",
    "#suffix = ['_{}_{}{}'.format(f.split('_')[1], 'p' if s>0 else 'm', abs(s)) for f in feats for s in shifts]\n",
    "\n",
    "def bayesian_generate_all(x_train, x_test):\n",
    "    shifts = [-10, -5, -1, 1, 5, 10]\n",
    "    feats = ['time_min', 'time_max']\n",
    "    x_train_new = []\n",
    "    x_test_new = []\n",
    "    for s in shifts:\n",
    "        for f in feats:\n",
    "            suffix = '_{}_{}{}'.format(f.split('_')[1], 'p' if s>0 else 'm', abs(s))\n",
    "            tmp_train, tmp_test = bayesian_time_diff(x_train, x_test, suffix, s, f)\n",
    "            tmp_train.drop(['time_min', 'time_max', 'Response'], axis=1, inplace=True)\n",
    "            tmp_test.drop(['time_min', 'time_max'], axis=1, inplace=True)\n",
    "            x_train_new.append(tmp_train)\n",
    "            x_test_new.append(tmp_test)\n",
    "    \n",
    "    x_train_new = x_train_new[0].join(x_train_new[1:])\n",
    "    x_test_new = x_test_new[0].join(x_test_new[1:])\n",
    "    \n",
    "    return x_train_new.values, x_test_new.values\n",
    "\n",
    "time_all = pd.read_csv('time_all.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "u = time_all.iloc[:1183747].copy()\n",
    "u.drop(['idx'], axis=1, inplace=True)\n",
    "v = time_all.iloc[1183747:].copy()\n",
    "v.drop(['idx', 'Response'], axis=1, inplace=True)\n",
    "\n",
    "u0, v0 = bayesian_generate_all(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train0 = read_pickle('x_train_date_feats_0.pickle')\n",
    "x_test = read_pickle('x_test_date_feats_0.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\Anaconda3\\envs\\kaggle\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "response = pd.read_csv('data/train_numeric.csv.zip', index_col=0, usecols=[0, 969])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train0 = response.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx0 = np.arange(x_train0.shape[0])\n",
    "x_train, x_val, y_train, y_val, idx_train, idx_val = train_test_split(x_train0, y_train0, idx0, \n",
    "                                                                      test_size=0.2, random_state=23435)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_train = time_all.iloc[idx_train].copy()\n",
    "time_train.drop(['idx'], axis=1, inplace=True)\n",
    "time_val = time_all.iloc[idx_val].copy()\n",
    "time_val.drop(['idx', 'Response'], axis=1, inplace=True)\n",
    "\n",
    "time_train, time_val = bayesian_generate_all(time_train, time_val)\n",
    "\n",
    "x_train = np.concatenate((x_train, time_train), axis=1)\n",
    "x_val = np.concatenate((x_val, time_val), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_train0 = time_all.iloc[:1183747].copy()\n",
    "time_train0.drop(['idx'], axis=1, inplace=True)\n",
    "time_test = time_all.iloc[1183747:].copy()\n",
    "time_test.drop(['idx', 'Response'], axis=1, inplace=True)\n",
    "\n",
    "time_train0, time_test = bayesian_generate_all(time_train0, time_test)\n",
    "\n",
    "x_train0 = np.concatenate((x_train0, time_train0), axis=1)\n",
    "x_test = np.concatenate((x_test, time_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv = StratifiedKFold(y_train, n_folds=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preds = np.ones(y_train.shape[0])\n",
    "for i, (train, test) in enumerate(cv):\n",
    "    clf.fit(x_train[train], y_train[train], \n",
    "                          eval_set=[(x_val, y_val)], eval_metric='auc', \n",
    "                          early_stopping_rounds=10)\n",
    "    models.append(clf)\n",
    "    preds[test] = clf.predict_proba(x_train[test])[:,1]\n",
    "    print(\"fold {}, ROC AUC: {:.3f}\".format(i, roc_auc_score(y_train[test], preds[test])))\n",
    "print(roc_auc_score(y_train, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.901478\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 400\n",
    "clf = XGBClassifier(max_depth=14, n_estimators=n_estimators, base_score=0.0058, n_jobs=8, colsample_bytree=0.6,\n",
    "                   min_child_weight=5, subsample=0.9,  reg_lambda=4, silent=False, learning_rate=0.03, random_state=12393)\n",
    "\n",
    "clf.fit(x_train, y_train, eval_set=[(x_val, y_val)], eval_metric='auc', early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf.best_ntree_limit:\n",
    "    n_estimators = int(clf.best_ntree_limit * 1.2)\n",
    "\n",
    "clf.n_estimators = n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train0, y_train0, eval_set=[(x_train0, y_train0)], eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(x_train0)\n",
    "preds = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "mcc = np.array([matthews_corrcoef(y_train0, preds>thr) for thr in thresholds])\n",
    "plt.plot(thresholds, mcc)\n",
    "best_threshold = thresholds[mcc.argmax()]\n",
    "print(mcc.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (clf.predict_proba(x_test)[:, 1]>best_threshold).astype(np.int8)\n",
    "sub = pd.read_csv('data/sample_submission.csv.zip', index_col=0)\n",
    "sub['Response'] = preds\n",
    "sub.to_csv('submission_train_time_features.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
